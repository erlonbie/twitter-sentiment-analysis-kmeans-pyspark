{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d676608b",
   "metadata": {},
   "source": [
    "## Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d479685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://erlonbie:****@nexus.apps.jusbr.com/repository/pypi-all/simple\n",
      "Collecting nltk\n",
      "  Downloading https://nexus.apps.jusbr.com/repository/pypi-all/packages/nltk/3.8.1/nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/erlonbie/.local/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /home/erlonbie/.local/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyspark\n",
    "#!pip install nltk\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c93b7",
   "metadata": {},
   "source": [
    "## Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad43945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/29 11:14:12 WARN Utils: Your hostname, erlonbie-xps139310 resolves to a loopback address: 127.0.1.1; using 192.168.0.143 instead (on interface wlp0s20f3)\n",
      "23/01/29 11:14:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/29 11:14:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# Desconecta o SparkContext, caso esteja conectado\n",
    "#sc.stop()\n",
    "\n",
    "# Opção 1\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"tp3\")\n",
    "\n",
    "# Opção 2 \n",
    "#conf = SparkConf().setMaster(\"spark://10.208.205.1:7077\").setAppName(\"UFAM-Lab1\")\n",
    "\n",
    "\n",
    "# Conecta ao Cluster Spark\n",
    "sc = SparkContext.getOrCreate(conf = conf) \n",
    "\n",
    "# Define um \"entry point\" para toda as operação SPARK SQL\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c497d6c",
   "metadata": {},
   "source": [
    "## Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "165f2f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+\n",
      "| id|label|               tweet|\n",
      "+---+-----+--------------------+\n",
      "|  1|    0| @user when a fat...|\n",
      "|  2|    0|@user @user thank...|\n",
      "|  3|    0|  bihday your maj...|\n",
      "|  4|    0|#model   i love u...|\n",
      "|  5|    0| factsguide: soci...|\n",
      "|  6|    0|[2/2] huge fan fa...|\n",
      "|  7|    0| @user camping to...|\n",
      "|  8|    0|the next school y...|\n",
      "|  9|    0|we won!!! love th...|\n",
      "| 10|    0| @user @user welc...|\n",
      "| 11|    0| â #ireland con...|\n",
      "| 12|    0|we are so selfish...|\n",
      "| 13|    0|i get to see my d...|\n",
      "| 14|    1|@user #cnn calls ...|\n",
      "| 15|    1|no comment!  in #...|\n",
      "| 16|    0|ouch...junior is ...|\n",
      "| 17|    0|i am thankful for...|\n",
      "| 18|    1|retweet if you ag...|\n",
      "| 19|    0|its #friday! ð...|\n",
      "| 20|    0|as we all know, e...|\n",
      "+---+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cases = sqlc.read.load(\"train.csv\",\n",
    "                       format=\"csv\", \n",
    "                       sep=\",\", \n",
    "                       inferSchema=\"true\", \n",
    "                       header=\"true\")\n",
    "cases.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a363af66",
   "metadata": {},
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a57db4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.fillna({'tweet':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fc57c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='tweet', outputCol='tokens')\n",
    "cases = tokenizer.transform(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bc818d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+--------------------+\n",
      "| id|label|               tweet|              tokens|\n",
      "+---+-----+--------------------+--------------------+\n",
      "|  1|    0| @user when a fat...|[@user, when, a, ...|\n",
      "|  2|    0|@user @user thank...|[@user, @user, th...|\n",
      "|  3|    0|  bihday your maj...|[bihday, your, ma...|\n",
      "|  4|    0|#model   i love u...|[#model, i, love,...|\n",
      "|  5|    0| factsguide: soci...|[factsguide:, soc...|\n",
      "|  6|    0|[2/2] huge fan fa...|[[2/2], huge, fan...|\n",
      "|  7|    0| @user camping to...|[@user, camping, ...|\n",
      "|  8|    0|the next school y...|[the, next, schoo...|\n",
      "|  9|    0|we won!!! love th...|[we, won!!!, love...|\n",
      "| 10|    0| @user @user welc...|[@user, @user, we...|\n",
      "| 11|    0| â #ireland con...|[â, #ireland, c...|\n",
      "| 12|    0|we are so selfish...|[we, are, so, sel...|\n",
      "| 13|    0|i get to see my d...|[i, get, to, see,...|\n",
      "| 14|    1|@user #cnn calls ...|[@user, #cnn, cal...|\n",
      "| 15|    1|no comment!  in #...|[no, comment!, in...|\n",
      "| 16|    0|ouch...junior is ...|[ouch...junior, i...|\n",
      "| 17|    0|i am thankful for...|[i, am, thankful,...|\n",
      "| 18|    1|retweet if you ag...|[retweet, if, you...|\n",
      "| 19|    0|its #friday! ð...|[its, #friday!, ð...|\n",
      "| 20|    0|as we all know, e...|[as, we, all, kno...|\n",
      "+---+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = cases.rdd.map(lambda x: (x['id'], x['label'], x['tweet'], list(filter(lambda x: x != '', x['tokens']))))\n",
    "cases = rdd.toDF(cases.columns)\n",
    "cases.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d2dd79",
   "metadata": {},
   "source": [
    "## K-means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134978ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF\n",
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4de37070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans Clustering \n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "numIterations = 200 \n",
    "numberClusters = 2\n",
    "kmeans = KMeans().setMaxIter(numIterations).setK(numberClusters).setSeed(1).setDistanceMeasure('cosine') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f1345",
   "metadata": {},
   "source": [
    "## Versão 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "29fdaff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+--------------------+\n",
      "| id|label|               tweet|              tokens|\n",
      "+---+-----+--------------------+--------------------+\n",
      "|  1|    0| @user when a fat...|[@user, when, a, ...|\n",
      "|  2|    0|@user @user thank...|[@user, @user, th...|\n",
      "|  3|    0|  bihday your maj...|[bihday, your, ma...|\n",
      "|  4|    0|#model   i love u...|[i, love, u, take...|\n",
      "|  5|    0| factsguide: soci...|[factsguide:, soc...|\n",
      "|  6|    0|[2/2] huge fan fa...|[[2/2], huge, fan...|\n",
      "|  7|    0| @user camping to...|[@user, camping, ...|\n",
      "|  8|    0|the next school y...|[the, next, schoo...|\n",
      "|  9|    0|we won!!! love th...|[we, won!!!, love...|\n",
      "| 10|    0| @user @user welc...|[@user, @user, we...|\n",
      "| 11|    0| â #ireland con...|[â, consumer, p...|\n",
      "| 12|    0|we are so selfish...|[we, are, so, sel...|\n",
      "| 13|    0|i get to see my d...|[i, get, to, see,...|\n",
      "| 14|    1|@user #cnn calls ...|[@user, calls, mi...|\n",
      "| 15|    1|no comment!  in #...|  [no, comment!, in]|\n",
      "| 16|    0|ouch...junior is ...| [ouch...junior, is]|\n",
      "| 17|    0|i am thankful for...|[i, am, thankful,...|\n",
      "| 18|    1|retweet if you ag...|[retweet, if, you...|\n",
      "| 19|    0|its #friday! ð...|[its, ð, smile...|\n",
      "| 20|    0|as we all know, e...|[as, we, all, kno...|\n",
      "+---+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = cases.rdd.map(lambda x:(x['id'], x['label'], x['tweet'], list(filter(lambda x: '#' not in x, x['tokens']))))\n",
    "cases_v1 = rdd.toDF(cases.columns)\n",
    "cases_v1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5264e193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokens</th>\n",
       "      <th>rawFeatures</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>[@user, when, a, father, is, dysfunctional, an...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 5.230670706306456, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>[@user, @user, thanks, for, credit, i, can't, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>[i, love, u, take, with, u, all, the, time, in...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>[factsguide:, society, now]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [@user, when, a, father, is, dysfunctional, an...   \n",
       "1  [@user, @user, thanks, for, credit, i, can't, ...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [i, love, u, take, with, u, all, the, time, in...   \n",
       "4                        [factsguide:, society, now]   \n",
       "\n",
       "                                         rawFeatures  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 5.230670706306456, 0.0, 0...  \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_v1 = hashingTF.transform(cases_v1)\n",
    "idfModel = idf.fit(cases_v1)\n",
    "cases_v1 = idfModel.transform(cases_v1)\n",
    "cases_v1.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c2348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"stdout writer for python3\" java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.ArrayList.<init>(ArrayList.java:156)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.toJava(EvaluatePython.scala:64)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.toJava(EvaluatePython.scala:58)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$javaToPython$1(Dataset.scala:3679)\n",
      "\tat org.apache.spark.sql.Dataset$$Lambda$3290/0x0000000100f31a68.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.ContextAwareIterator.next(ContextAwareIterator.scala:41)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:90)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:80)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:80)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:732)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread$$Lambda$3174/0x0000000100828000.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "Exception in thread \"stdout writer for python3\" java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.unsafe.types.UTF8String.getBytes(UTF8String.java:258)\n",
      "\tat org.apache.spark.unsafe.types.UTF8String.toString(UTF8String.java:1355)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.toJava(EvaluatePython.scala:81)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$toJava$1(EvaluatePython.scala:66)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$toJava$1$adapted(EvaluatePython.scala:65)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$$Lambda$3297/0x0000000100f47000.apply(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.util.ArrayData.foreach(ArrayData.scala:184)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.toJava(EvaluatePython.scala:65)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.toJava(EvaluatePython.scala:58)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$javaToPython$1(Dataset.scala:3679)\n",
      "\tat org.apache.spark.sql.Dataset$$Lambda$3290/0x0000000100f31a68.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.ContextAwareIterator.next(ContextAwareIterator.scala:41)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:90)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:80)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:80)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:732)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread$$Lambda$3174/0x0000000100828000.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "\r",
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/29 15:25:33 ERROR Utils: Uncaught exception in thread stdout writer for python3\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.ArrayList.<init>(ArrayList.java:156)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.toJava(EvaluatePython.scala:64)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.toJava(EvaluatePython.scala:58)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$javaToPython$1(Dataset.scala:3679)\n",
      "\tat org.apache.spark.sql.Dataset$$Lambda$3290/0x0000000100f31a68.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.ContextAwareIterator.next(ContextAwareIterator.scala:41)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:90)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:80)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:80)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:732)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread$$Lambda$3174/0x0000000100828000.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "23/01/29 15:25:33 ERROR Utils: Uncaught exception in thread stdout writer for python3\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.unsafe.types.UTF8String.getBytes(UTF8String.java:258)\n",
      "\tat org.apache.spark.unsafe.types.UTF8String.toString(UTF8String.java:1355)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.toJava(EvaluatePython.scala:81)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$toJava$1(EvaluatePython.scala:66)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.$anonfun$toJava$1$adapted(EvaluatePython.scala:65)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$$$Lambda$3297/0x0000000100f47000.apply(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.util.ArrayData.foreach(ArrayData.scala:184)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.toJava(EvaluatePython.scala:65)\n",
      "\tat org.apache.spark.sql.execution.python.EvaluatePython$.toJava(EvaluatePython.scala:58)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$javaToPython$1(Dataset.scala:3679)\n",
      "\tat org.apache.spark.sql.Dataset$$Lambda$3290/0x0000000100f31a68.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.ContextAwareIterator.next(ContextAwareIterator.scala:41)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:90)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:80)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:80)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:732)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread$$Lambda$3174/0x0000000100828000.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/29 21:06:51 WARN TransportChannelHandler: Exception in connection from /192.168.0.143:46801\n",
      "java.io.IOException: Connection timed out\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:47)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:339)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:293)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:268)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:425)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:258)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "kmeans_model = kmeans.fit(cases_v1)\n",
    "predictions_v1 = kmeans_model.transform(cases_v1)\n",
    "predictions_v1.select('id','tweet','label','prediction').limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1e245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d627132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet\n",
       "0    1      0   @user when a father is dysfunctional and is s...\n",
       "1    2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2    3      0                                bihday your majesty\n",
       "3    4      0  #model   i love u take with u all the time in ...\n",
       "4    5      0             factsguide: society now    #motivation\n",
       "5    6      0  [2/2] huge fan fare and big talking before the...\n",
       "6    7      0   @user camping tomorrow @user @user @user @use...\n",
       "7    8      0  the next school year is the year for exams.ð...\n",
       "8    9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9   10      0   @user @user welcome here !  i'm   it's so #gr...\n",
       "10  11      0   â #ireland consumer price index (mom) climb...\n",
       "11  12      0  we are so selfish. #orlando #standwithorlando ...\n",
       "12  13      0  i get to see my daddy today!!   #80days #getti...\n",
       "13  14      1  @user #cnn calls #michigan middle school 'buil...\n",
       "14  15      1  no comment!  in #australia   #opkillingbay #se...\n",
       "15  16      0  ouch...junior is angryð#got7 #junior #yugyo...\n",
       "16  17      0  i am thankful for having a paner. #thankful #p...\n",
       "17  18      1                             retweet if you agree! \n",
       "18  19      0  its #friday! ð smiles all around via ig use...\n",
       "19  20      0  as we all know, essential oils are not made of..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Converter para dataframe Pandas\n",
    "import pandas as pd\n",
    "\n",
    "cases.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ece5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = cases.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2249f27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet\n",
       "0    1      0   @user when a father is dysfunctional and is s...\n",
       "1    2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2    3      0                                bihday your majesty\n",
       "3    4      0  #model   i love u take with u all the time in ...\n",
       "4    5      0             factsguide: society now    #motivation\n",
       "5    6      0  [2/2] huge fan fare and big talking before the...\n",
       "6    7      0   @user camping tomorrow @user @user @user @use...\n",
       "7    8      0  the next school year is the year for exams.ð...\n",
       "8    9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9   10      0   @user @user welcome here !  i'm   it's so #gr...\n",
       "10  11      0   â #ireland consumer price index (mom) climb...\n",
       "11  12      0  we are so selfish. #orlando #standwithorlando ...\n",
       "12  13      0  i get to see my daddy today!!   #80days #getti...\n",
       "13  14      1  @user #cnn calls #michigan middle school 'buil...\n",
       "14  15      1  no comment!  in #australia   #opkillingbay #se...\n",
       "15  16      0  ouch...junior is angryð#got7 #junior #yugyo...\n",
       "16  17      0  i am thankful for having a paner. #thankful #p...\n",
       "17  18      1                             retweet if you agree! \n",
       "18  19      0  its #friday! ð smiles all around via ig use...\n",
       "19  20      0  as we all know, essential oils are not made of..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b310fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we won!!! love the land!!!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "a1 = \"we won!!! love the land!!! #allin #cavs #champ\"\n",
    "a2 =\" \".join(filter(lambda x:x[0]!='#', a1.split()))\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "214b37d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtra(x):\n",
    "    return \" \".join(filter(lambda y:y[0]!='#', x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d6a0aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste['tweet'] = df_teste['tweet'].apply(filtra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1bdfbb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for credit i can't use caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i love u take with u all the time in urð±!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @user...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! â¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here ! i'm it's so !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â consumer price index (mom) climbed from pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user calls middle school 'build the wall' cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment! in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ouch...junior is angryð#got7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>i am thankful for having a paner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>its ð smiles all around via ig user: @user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet\n",
       "0    1      0  @user when a father is dysfunctional and is so...\n",
       "1    2      0  @user @user thanks for credit i can't use caus...\n",
       "2    3      0                                bihday your majesty\n",
       "3    4      0  i love u take with u all the time in urð±!!!...\n",
       "4    5      0                            factsguide: society now\n",
       "5    6      0  [2/2] huge fan fare and big talking before the...\n",
       "6    7      0  @user camping tomorrow @user @user @user @user...\n",
       "7    8      0  the next school year is the year for exams.ð...\n",
       "8    9      0                     we won!!! love the land!!! â¦\n",
       "9   10      0           @user @user welcome here ! i'm it's so !\n",
       "10  11      0  â consumer price index (mom) climbed from pr...\n",
       "11  12      0                                 we are so selfish.\n",
       "12  13      0                      i get to see my daddy today!!\n",
       "13  14      1  @user calls middle school 'build the wall' cha...\n",
       "14  15      1                                     no comment! in\n",
       "15  16      0                    ouch...junior is angryð#got7\n",
       "16  17      0                  i am thankful for having a paner.\n",
       "17  18      1                              retweet if you agree!\n",
       "18  19      0  its ð smiles all around via ig user: @user ...\n",
       "19  20      0  as we all know, essential oils are not made of..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ee4065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/erlonbie/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e828a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3589b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words(df):\n",
    "    df['stopwords'] = df['tweet'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "    print(df[['tweet','stopwords']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87fbc4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  stopwords\n",
      "0   @user when a father is dysfunctional and is s...         10\n",
      "1  @user @user thanks for #lyft credit i can't us...          5\n",
      "2                                bihday your majesty          1\n",
      "3  #model   i love u take with u all the time in ...          5\n",
      "4             factsguide: society now    #motivation          1\n"
     ]
    }
   ],
   "source": [
    "stop_words(cases.toPandas())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
